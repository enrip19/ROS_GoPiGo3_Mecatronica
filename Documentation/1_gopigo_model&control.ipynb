{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gopigo3 model & navigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final objective of this chapter are:\n",
    "- Create a model of our gopigo3 robot \n",
    "- create a model of the virtual environment\n",
    "- locate the robot in our created environment\n",
    "- use gazebo package to simulate the robot kinematics and dynamics\n",
    "- use rviz package to view the different topics and nodes\n",
    "\n",
    "The final model represents the real gopigo3 robot we will use in the laboratory\n",
    "\n",
    "Interesting complementary information could be found:\n",
    "\n",
    "https://brjapon.medium.com/learning-robotics-with-ros-made-easy-12197c918dab\n",
    "\n",
    "http://wiki.ros.org/Robots/gopigo3\n",
    "\n",
    "https://robots.ros.org/gopigo3/\n",
    "\n",
    "https://github.com/ros-gopigo3/gopigo3\n"
   ]
  },
  {
   "source": [
    "<img src=\"./Images/1_gopigo3_UB.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1. rUBot gopigo3 model generation\n",
    "\n",
    "First of all, we have to create the \"gopigo3_description\" package containing the gopigo3 model:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-cfa0bc0538d8>, line 1)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-cfa0bc0538d8>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    cd ~/gopigo_pc_ws/src\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "cd ~/gopigo_pc_ws/src\n",
    "catkin_create_pkg gopigo3_description rospy\n",
    "cd ..\n",
    "catkin_make"
   ]
  },
  {
   "source": [
    "Then open the .bashrc file and verify the ROS_IP and ROS_MASTER_URI environment variables and source to the proper workspace:\n",
    "\n",
    "source ~/gopigo_pc_ws/devel/setup.bash\n",
    "\n",
    "export ROS_IP=192.168.18.121 (specify here your VM IP)\n",
    "\n",
    "export ROS_MASTER_URI=http://localhost:11311"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "To create our robot model, we use URDF files (Unified Robot Description Format). URDF file is an XML format file for representing a robot model.(http://wiki.ros.org/urdf/Tutorials)\n",
    "\n",
    "We have created 2 folders for model description:\n",
    "- URDF: folder where different URDF models are located\n",
    "- meshes: folder where 3D body models in stl format are located."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The main parts of URDF model are:\n",
    "- links: diferent bodies/plastic elements\n",
    "- joints: connection between 2 links \n",
    "- sensors & actuators plugins (2D camera, LIDAR and DC motors)\n",
    "\n",
    "The link definition contains:\n",
    "- visual properties: the origin, geometry and material\n",
    "- collision properties: the origin and geomnetry\n",
    "- inertial properties: the origin, mass and inertia matrix\n",
    "\n",
    "The joint definition contains:\n",
    "- joint Type (fixed, continuous)\n",
    "- parent and child frames\n",
    "- origin frame\n",
    "- rotation axis\n",
    "\n",
    "In the case or wright wheel:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<!-- Right Wheel -->\n",
    "  <link name=\"right_wheel\">\n",
    "    <visual>\n",
    "      <origin xyz=\"0 0 0\" rpy=\"1.570795 0 0\" />\n",
    "      <geometry>\n",
    "          <cylinder length=\"0.05\" radius=\"0.1\" />\n",
    "      </geometry>\n",
    "      <material name=\"orange\"/>\n",
    "    </visual>\n",
    "    <collision>\n",
    "      <origin xyz=\"0 0 0\" rpy=\"1.570795 0 0\" />\n",
    "      <geometry>\n",
    "          <cylinder length=\"0.05\" radius=\"0.1\" />\n",
    "      </geometry>\n",
    "    </collision>\n",
    "    <inertial>\n",
    "      <origin xyz=\"0 0 0\" rpy=\"1.570795 0 0\" />\n",
    "      <mass value=\"0.15\"/>\n",
    "      <inertia ixx=\"0.01\" ixy=\"0.0\" ixz=\"0.0\" iyy=\"0.005\" iyz=\"0.0\" izz=\"0.005\"/>\n",
    "    </inertial>\n",
    "  </link>\n",
    "  \n",
    "  <!-- Right Wheel joint -->\n",
    "  <joint name=\"joint_right_wheel\" type=\"continuous\">\n",
    "    <parent link=\"base_link\"/>\n",
    "    <child link=\"right_wheel\"/>\n",
    "    <origin xyz=\"0 -0.30 0.025\" rpy=\"0 0 0\" /> \n",
    "    <axis xyz=\"0 1 0\" />\n",
    "  </joint>"
   ]
  },
  {
   "source": [
    "The gopigo3 model includes different sensors and actuators:\n",
    "\n",
    "Sensors:\n",
    "- a two-dimensional camera: correspondas to RBPi camera\n",
    "- a 360ยบ LIDAR sensor: corresponds to the EAI YDLIDAR X4 (https://www.robotshop.com/es/es/escaner-laser-360-ydlidar-x4.html)\n",
    "\n",
    "Actuator:\n",
    "- Differential drive actuator: based on 2 DC motors with encoders to obtain the Odometry information\n",
    "\n",
    "The full model contains also information about the sensor and actuator controllers using specific Gazebo plugins (http://gazebosim.org/tutorials?tut=ros_gzplugins#Tutorial:UsingGazebopluginswithROS). \n",
    "\n",
    "Gazebo plugins give your URDF models greater functionality and can tie in ROS messages and service calls for sensor output and motor input. \n",
    "\n",
    "These plugins can be referenced through a URDF file, and to insert them in the URDF file, you have to follow the sintax:\n",
    "- for Differential drive actuator:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<robot>\n",
    "  ... robot description ...\n",
    "  <gazebo>\n",
    "    <plugin name=\"differential_drive_controller\" filename=\"libdiffdrive_plugin.so\">\n",
    "      ... plugin parameters ...\n",
    "    </plugin>\n",
    "  </gazebo>\n",
    "  ... robot description ...\n",
    "</robot>"
   ]
  },
  {
   "source": [
    "<img src=\"./Images/1_Drive_kine.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "- for sensor plugin:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<robot>\n",
    "  ... robot description ...\n",
    "  <link name=\"sensor_link\">\n",
    "    ... link description ...\n",
    "  </link>\n",
    "\n",
    "  <gazebo reference=\"sensor_link\">\n",
    "    <sensor type=\"camera\" name=\"camera1\">\n",
    "      ... sensor parameters ...\n",
    "      <plugin name=\"camera_controller\" filename=\"libgazebo_ros_camera.so\">\n",
    "        ... plugin parameters ..\n",
    "      </plugin>\n",
    "    </sensor>\n",
    "  </gazebo>\n",
    "\n",
    "</robot>"
   ]
  },
  {
   "source": [
    "The diferent model files in urdf folder are:\n",
    "- gopigo_basic.gazebo: includes only the geometrical description of gopigo robot.\n",
    "- gopigo3_basic.gazebo: includes sensors and actuator:\n",
    "    - the 2D camera and LDS sensors\n",
    "    - the differential drive actuator\n",
    "- gopigo3_init.gazebo: includes sensors and actuator:\n",
    "    - the 2D camera, LDS and LIDAR sensors\n",
    "    - the differential drive actuator\n",
    "- gopigo3.gazebo: includes corrections in the proposed model:\n",
    "    - base_link geometry and inertia\n",
    "    - 2D camera real position\n",
    "    - LIDAR scaling and orientation\n",
    "\n",
    "We use a specific \"gopigo3_rviz.launch\" launch file where we specify the robot model we want to open in rviz with a configuration specified in \"gopigo3_model.rviz\":"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<?xml version=\"1.0\"?>\n",
    "<launch>\n",
    "<!-- set these parameters on Parameter Server -->\n",
    "   <param name=\"robot_description\" textfile=\"$(find gopigo3_description)/urdf/gopigo_basic.gazebo\" />\n",
    "  <!-- send fake joint values -->\n",
    "  <node name=\"joint_state_publisher\" pkg=\"joint_state_publisher\" type=\"joint_state_publisher\">\n",
    "    <param name=\"use_gui\" value=\"False\"/>\n",
    "  </node>\n",
    "  <!-- Combine joint values -->\n",
    "  <node name=\"robot_state_publisher\" pkg=\"robot_state_publisher\" type=\"robot_state_publisher\"/>\n",
    "  <!-- Show in Rviz   -->\n",
    "  <node name=\"rviz\" pkg=\"rviz\" type=\"rviz\"  args=\"-d $(find gopigo3_description)/rviz/gopigo3_model.rviz\"/>\n",
    "</launch>"
   ]
  },
  {
   "source": [
    "Launch the ROS visualization tool to check that the model is properly built. \n",
    "RViz only represents the robot visual features. You have available all the options to check every aspect of the appearance of the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "roslaunch gopigo3_description gopigo_basic_rviz.launch"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "<img src=\"./Images/1_gopigo_basic_rviz.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "roslaunch gopigo3_description gopigo3_rviz.launch"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "<img src=\"./Images/1_gopigo3_rviz.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### gopigo3 model improvements\n",
    "Some modifications in the initial model \"gopigo3_init.gazebo\" have been made to:\n",
    "- locate the LIDAR in the correct position\n",
    "- locate the camera axis in front position to see properly"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Special attention has to be done to the YDLIDAR sensor.\n",
    "\n",
    "- YDLIDAR X4 is a 360-degree two-dimensional rangefinder (hereinafter referred to as X4) developed by YDLIDAR team. \n",
    "- Based on the principle of triangulation, it is equipped with related optics, electronics and algorithm design to achieve high-frequency and high-precision distance measurement. \n",
    "- The mechanical structure rotates 360 degrees to continuously output the angle information as well as the point cloud data of the scanning environment while ranging.\n",
    "-10m Ranging distance (2cm absolute error)"
   ]
  },
  {
   "source": [
    "<img src=\"./Images/LP01_ydlidar.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "It is important to note that:\n",
    "- the number of points of real YDLidar is 720 (one each half degree)\n",
    "- the number of points of simulated Lidar is 360 (one each degree)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Exercise 1:\n",
    "\n",
    "Modify the gopigo3.gazebo model to take into account:\n",
    "- Adapt the base-link geometry and inertia to the real gopigo3 robot"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<img src=\"./Images/1_mides.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## rUBot gopigo3 spawn in world environment\n",
    "\n",
    "In robotics research, always before working with a real robot, we simulate the robot behaviour in a virtual environment close to the real one. The dynamic simulation of a robot, is a better approach to examining the actual behavior of the robot rather than just using software. Rigid body mechanics, including mass and inertia, friction, damping, motor controllers, sensor detection properties, noise signals, and every aspect of the robot and the environment that can be retained in a model with reasonable accuracy is much less expensive when replicated in a simulator than if you tried to do this with physical hardware.\n",
    "\n",
    "Gazebo is an open source 3D robotics simulator and includes an ODE physics engine and OpenGL rendering, and supports code integration for closed-loop control in robot drives. This is sensor simulation and actuator control.\n",
    "\n",
    "A specific ROS Package called \"gazebo_control\" have been created for this purpose."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roslaunch gazebo_control spawn.launch\n",
    "roslaunch gopigo3_description gopigo3_rviz.launch"
   ]
  },
  {
   "source": [
    "<img src=\"./Images/LP02_rubotcoop_spawn.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<img src=\"./Images/1_gopigo3_gazebo.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "You can see the nodes and topics generated using rqt_graph"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<img src=\"./Images/LP05_rqt_gopigo.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "In order to kill the previous Gazebo process, type:\n",
    "\n",
    "killall gzserver && killall gzclient\n",
    "\n",
    "or type ctrl+r and kill"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 2. Design the Project world\n",
    "\n",
    "Here we have first to design the project world, for exemple a maze from where our rUBot gopigo3 has to navigate autonomously.\n",
    "\n",
    "There is a very useful and simple tool to design a proper world: Building editor\" in gazebo.\n",
    "\n",
    "Open gazebo as superuser:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sudo gazebo"
   ]
  },
  {
   "source": [
    "You can build your world using \"Building Editor\" in Edit menu"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<img src=\"./Images/LP03_BuildingWorld1_1.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "You can save:\n",
    "- the generated model in a model folder (without extension)\n",
    "\n",
    "Close the Builder Editor, modify the model position and add other elements if needed. Save:\n",
    "- the generated world (with extension .world) in the world folder.\n",
    "\n",
    "Once you finish is better to close the terminal you have work as superuser\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Exercise 2:\n",
    "Generate a proper world defined by the schematic proposed below"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<img src=\"./Images/1_maze.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Spawn the gopigo robot\n",
    "\n",
    "Now, spawn the rUBotCoop robot in our generated world. You have to create a \"rubot_navigation.launch\" file:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<launch>\n",
    "  <arg name=\"world\" default=\"world1.world\"/> \n",
    "  <arg name=\"model\" default=\"gopigo3.gazebo\" />\n",
    "  <arg name=\"x_pos\" default=\"0.0\"/>\n",
    "  <arg name=\"y_pos\" default=\"0.0\"/>\n",
    "  <arg name=\"z_pos\" default=\"0.0\"/>\n",
    "\n",
    "  <include file=\"$(find gazebo_ros)/launch/empty_world.launch\">\n",
    "    <arg name=\"world_name\" value=\"$(find gazebo_control)/worlds/$(arg world)\"/>\n",
    "    <arg name=\"paused\" value=\"false\"/>\n",
    "    <arg name=\"use_sim_time\" value=\"true\"/>\n",
    "    <arg name=\"gui\" value=\"true\"/>\n",
    "    <arg name=\"headless\" value=\"false\"/>\n",
    "    <arg name=\"debug\" value=\"false\"/>\n",
    "  </include>\n",
    "\n",
    "  <param name=\"robot_description\" textfile=\"$(find gopigo3_description)/urdf/$(arg model)\" />\n",
    "  \n",
    "  <node pkg=\"gazebo_ros\" type=\"spawn_model\" name=\"spawn_urdf\"\n",
    "    args=\"-urdf -model gopigo3 -x $(arg x_pos) -y $(arg y_pos) -z $(arg z_pos) -param robot_description\" />\n",
    "\n",
    "</launch>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roslaunch gazebo_control rubot_navigation.launch"
   ]
  },
  {
   "source": [
    "<img src=\"./Images/LP04_BuildingWorld1_2.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "To control the robot with the Keyboard you have to install the \"teleop-tools\" package:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sudo apt-get install ros-melodic-teleop-tools"
   ]
  },
  {
   "source": [
    "Then you will be able to control the robot with the Keyboard typing:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rosrun key_teleop key_teleop.py /key_vel:=/cmd_vel"
   ]
  },
  {
   "source": [
    "## 3. rUBot gopigo navigation control in the new world environment\n",
    "\n",
    "Once the world has been generated we will create a ROS Package \"rubot_control\" to perform the autonomous navigation "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/gopigo_pc_ws/src\n",
    "catkin_create_pkg rubot_control rospy std_msgs sensor_msgs geometry_msgs nav_msgs\n",
    "cd ..\n",
    "catkin_make"
   ]
  },
  {
   "source": [
    "<img src=\"./Images/LP07_rubot_control.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "We will create now different navigation python files in \"src\" folder:\n",
    "- move1_gopigo.py: to define a rubot movement with linear and angular speed\n",
    "- move2_gopigo_param.py: to perform the same operation using params\n",
    "- move3_gopigo_distance.py: to specify a maximum distance\n",
    "\n",
    "Specific launch files have been created to launch the nodes and python files created above:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roslaunch rubot_control rubot_move1.launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roslaunch rubot_control rubot_move2.launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roslaunch rubot_control rubot_move3.launch"
   ]
  },
  {
   "source": [
    "<img src=\"./Images/1_rubot_move3.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## rUBot gopigo autonomous navigation and obstacle avoidance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "In order to navigate autonomously and avoid obstacles, we have created diferent python files in \"src\" folder:\n",
    "- rubot_LIDAR_Test.py: to test the LIDAR distance readings and angles\n",
    "- rubot_autonomous_navigation1.py: to perform a simple algorithm for navigation with obstacle avoidance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "we will create also a \"launch\" folder including the corresponding launch files:\n",
    "- rubot_lidar_test.launch\n",
    "- rubot_nav1.launch"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### 1. LIDAR test\n",
    "We have created a world to test the rubot model. This world is based on a wall to verify that the LIDAR see the obstacle in the correct angle. We have to launch the \"rubot_lidar_test.launch\" file in the \"rubot_control\" package."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "roslaunch rubot_control rubot_lidar_test.launch"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "<img src=\"./Images/1_rubot_test.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### 2. Autonomous navigation with obstacle avoidance\n",
    "We will use now the created world to test the autonomous navigation with obstacle avoidance performance. \n",
    "\n",
    "We have to launch the \"rubot_nav1.launch\" file in the \"rubot_control\" package."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roslaunch rubot_control rubot_nav1.launch"
   ]
  },
  {
   "source": [
    "Careful:\n",
    "- we have included in launch file: gazebo spawn, rviz visualization and rubot_nav node execution \n",
    "- In rviz you have to change the fixed frame to \"odom\" frame"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<img src=\"./Images/LP08_rubot_nav_key.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The algorithm description functionality is:\n",
    "- \"rubot_autonomous_navigation1.py\": The Python script makes the robot go forward. \n",
    "    - LIDAR is allways searching the closest distance and the angle\n",
    "    - when this distance is lower than a threshold, the robot goes backward with angular speed in the oposite direction of the minimum distance angle.\n",
    "\n",
    "The node and topics graph:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<img src=\"./Images/01_rubot_nav_rqt.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Exercise 3:\n",
    "\n",
    "Create another rubot_autonomous_navigation.py file to improve the navigation process of our gopigo3 rubot for exemple to follow the wall on the right side."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}